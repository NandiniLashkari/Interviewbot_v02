<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>InterviewBot - Virtual Interview</title>
    <style>
        body {
            margin: 0;
            background: linear-gradient(to bottom right, #000000, #212191);
            font-family: 'Segoe UI', sans-serif;
            overflow: hidden;
            color: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        header {
            background: #1a1a40;
            padding: 1rem;
            text-align: center;
            font-size: clamp(1.5rem, 4vw, 1.8rem);
            color: #0ff;
            box-shadow: 0 2px 10px #0ff4;
            z-index: 10;
        }
        main {
            position: relative;
            width: 100%;
            flex: 1;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        #three-container {
            position: relative;
            width: 70%; /* Increased from 60% */
            max-width: 900px; /* Adjusted max-width for larger screens */
            height: 70%;
            max-height: 600px;
            background-image: url('https://images.unsplash.com/photo-1516321310764-8a42f8b6f8b0'); /* Formal office background */
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            border-radius: 12px;
            box-shadow: 0 0 15px #0ff6;
            z-index: 1;
        }
        #webcamFeed {
            position: absolute;
            bottom: 2rem;
            right: 2rem;
            width: 250px; /* Increased from 200px */
            height: 187.5px; /* Adjusted for 4:3 aspect ratio */
            border-radius: 8px;
            border: 2px solid #0ff;
            box-shadow: 0 0 10px #0ff;
            z-index: 5;
        }
        .controls {
            position: absolute;
            bottom: 2rem;
            left: 50%;
            transform: translateX(-50%);
            z-index: 5;
            display: flex;
            gap: 1rem;
        }
        button {
            background: #0ff;
            color: #000;
            border: none;
            padding: 0.8rem 1.5rem;
            font-size: clamp(0.9rem, 2.5vw, 1rem);
            border-radius: 8px;
            cursor: pointer;
            box-shadow: 0 0 10px #0ff, 0 0 20px #0ff6;
        }
        button:hover {
            background: #0cc;
        }
        footer {
            background: #1a1a40;
            padding: 0.5rem;
            text-align: center;
            font-size: clamp(0.8rem, 2vw, 0.9rem);
            color: #0ff;
            z-index: 10;
        }
        #questionDisplay {
            position: absolute;
            bottom: 6rem; /* Positioned above controls */
            left: 50%;
            transform: translateX(-50%);
            color: #fff;
            font-size: clamp(0.9rem, 2.5vw, 1.2rem);
            text-align: center;
            z-index: 5;
            background: rgba(26, 26, 64, 0.8);
            padding: 0.5rem 1rem;
            border-radius: 6px;
            max-width: 90%;
            line-height: 1.4;
            text-shadow: 0 0 5px #0ff;
        }
        #viewReportButton {
            display: none;
        }
        @media (max-width: 768px) {
            #three-container {
                width: 80%; /* Adjusted from 80% */
                height: 60%;
            }
            #webcamFeed {
                width: 200px; /* Increased from 150px */
                height: 150px; /* Adjusted for 4:3 aspect ratio */
                bottom: 1rem;
                right: 1rem;
            }
            .controls {
                flex-direction: column;
                align-items: center;
                bottom: 1rem;
            }
            button {
                padding: 0.6rem 1.2rem;
            }
            #questionDisplay {
                bottom: 5rem;
                font-size: clamp(0.8rem, 2vw, 1rem);
                max-width: 95%;
            }
        }
        @media (max-width: 480px) {
            header, footer {
                font-size: clamp(1rem, 3vw, 1.2rem);
            }
            #three-container {
                width: 90%; /* Adjusted from 90% */
                height: 50%;
            }
            #webcamFeed {
                width: 150px; /* Increased from 120px */
                height: 112.5px; /* Adjusted for 4:3 aspect ratio */
            }
            button {
                font-size: clamp(0.8rem, 2vw, 0.9rem);
            }
            #questionDisplay {
                bottom: 4rem;
                font-size: clamp(0.7rem, 1.8vw, 0.9rem);
            }
        }
    </style>
</head>
<body>
    <header>InterviewBot - Your Virtual Interview</header>
    <main>
        <div id="three-container"></div>
        <video id="webcamFeed" autoplay playsinline></video>
        <div class="controls">
            <button id="toggleListenButton">Start Listening</button>
            <button id="viewReportButton">View Report</button>
        </div>
        <div id="questionDisplay"></div>
    </main>
    <footer>© 2025 InterviewBot. All rights reserved.</footer>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    <script>
        // Function to clean text
        function cleanText(text) {
            return text.replace(/[\*•\-\n]+/g, ' ').replace(/\s+/g, ' ').trim();
        }

        // Function to select a female voice for Web Speech API
        function getFemaleVoice() {
            const voices = window.speechSynthesis.getVoices();
            const femaleVoice = voices.find(voice => 
                voice.name.toLowerCase().includes('female') ||
                voice.name.includes('Samantha') ||
                voice.name.includes('Victoria') ||
                voice.name.includes('Tessa') ||
                voice.name.includes('Zira') ||
                voice.lang.includes('en-US')
            );
            return femaleVoice || voices[0];
        }

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(80, window.innerWidth / window.innerHeight, 0.2, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth * 0.7, window.innerHeight * 0.7); // Match increased three-container width
        document.getElementById('three-container').appendChild(renderer.domElement);
        const controls = new THREE.OrbitControls(camera, renderer.domElement);
        controls.enablePan = true;
        controls.enableZoom = true;
        controls.enableRotate = true;
        camera.position.set(0, -0.3, 1.5);
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);
        const dirLight = new THREE.DirectionalLight(0xffffff, 0.5);
        dirLight.position.set(7, 10, 7);
        scene.add(dirLight);
        let headMesh, recognition;
        let isSpeaking = false;
        let isListening = false;
        let userName = "User";
        let mixer = null;
        let idleAction = null;
        let bowGreeetAction = null;
        let thinkingAction = null;
        let talking2Action = null;
        let model = null;
        let rootBone = null;
        let eyesClosedIndex = -1;
        let blinkState = 'open';
        let blinkTimer = 0;
        let nextBlink = Math.random() * 3 + 2;
        const blinkDuration = 0.2;
        const clock = new THREE.Clock();
        let interviewQuestions = [];
        let currentQuestionIndex = 0;
        let questionNumber = 1;
        let isInterviewMode = false;
        let interviewAnswers = [];
        let screenRecorder;
        let recordedChunks = [];
        let userData = null;
        let fullTranscript = '';
        let silenceTimer = null;
        const SILENCE_TIMEOUT = 6000;
        const MAX_LISTENING_TIME = 60000;

        async function initWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                const webcamFeed = document.getElementById('webcamFeed');
                webcamFeed.srcObject = stream;
            } catch (err) {
                console.error('Error accessing webcam:', err);
                alert('Failed to access webcam. Please allow camera permissions.');
            }
        }

        const loader = new THREE.GLTFLoader();
        loader.load('/static/models/Asian_withoutlight.glb', async (gltf) => {
            model = gltf.scene;
            model.scale.set(0.1, 0.1, 0.1);
            model.position.set(0, 0, 0);
            model.rotation.set(0, 0, 0);
            scene.add(model);
            camera.lookAt(0, -0.5, -0.2);
            if (gltf.animations && gltf.animations.length > 0) {
                mixer = new THREE.AnimationMixer(model);
                function filterRotationTracks(clip) {
                    if (!clip.tracks) return clip;
                    clip.tracks = clip.tracks.filter(track => {
                        const isRotation = track.name.toLowerCase().includes('rotation') || track.name.toLowerCase().includes('quaternion');
                        const isRoot = track.name.toLowerCase().includes('root') || track.name.toLowerCase().includes('spine') || track.name.toLowerCase().includes('hips');
                        return !(isRotation && isRoot);
                    });
                    return clip;
                }
                const idleClip = gltf.animations.find(anim => anim.name.toLowerCase().includes('idle'));
                if (idleClip) {
                    idleAction = mixer.clipAction(idleClip);
                    idleAction.setLoop(THREE.LoopRepeat);
                    idleAction.play();
                }
                const bowGreeetClip = gltf.animations.find(anim => anim.name.toLowerCase().includes('bowgreeet'));
                if (bowGreeetClip) {
                    filterRotationTracks(bowGreeetClip);
                    bowGreeetAction = mixer.clipAction(bowGreeetClip);
                    bowGreeetAction.setLoop(THREE.LoopOnce);
                    bowGreeetAction.clampWhenFinished = false;
                }
                const thinkingClip = gltf.animations.find(anim => anim.name.toLowerCase().includes('thinking'));
                if (thinkingClip) {
                    filterRotationTracks(thinkingClip);
                    thinkingAction = mixer.clipAction(thinkingClip);
                    thinkingAction.setLoop(THREE.LoopRepeat);
                }
                const talking2Clip = gltf.animations.find(anim => anim.name.toLowerCase().includes('talking2'));
                if (talking2Clip) {
                    filterRotationTracks(talking2Clip);
                    talking2Action = mixer.clipAction(talking2Clip);
                    talking2Action.setLoop(THREE.LoopRepeat);
                }
            }
            model.traverse((child) => {
                if (child.isMesh) {
                    child.material.metalness = 0.1;
                    child.material.roughness = 0.7;
                    child.material.colorSpace = THREE.SRGBColorSpace;
                }
                if (child.name === 'Asian_female_head001') {
                    headMesh = child;
                    if (child.morphTargetDictionary) {
                        eyesClosedIndex = Object.keys(child.morphTargetDictionary).indexOf('eyesClosed');
                    }
                }
                if (child.isBone && child.name.toLowerCase().includes('root')) {
                    rootBone = child;
                }
            });
            const data = await fetchUserData();
            if (data) {
                userData = data;
                userName = data.name || 'User';
                try {
                    const stream = await navigator.mediaDevices.getDisplayMedia({
                        video: true,
                        audio: true
                    });
                    screenRecorder = new MediaRecorder(stream);
                    screenRecorder.ondataavailable = (e) => {
                        if (e.data.size > 0) recordedChunks.push(e.data);
                    };
                    screenRecorder.onstop = () => {
                        const blob = new Blob(recordedChunks, { type: "video/webm" });
                        const url = URL.createObjectURL(blob);
                        const a = document.createElement("a");
                        a.href = url;
                        a.download = "interview_recording.webm";
                        document.body.appendChild(a);
                        a.click();
                        setTimeout(() => {
                            document.body.removeChild(a);
                            window.URL.revokeObjectURL(url);
                        }, 100);
                    };
                    screenRecorder.start();
                } catch (err) {
                    alert("Screen recording permission denied or failed.");
                }
                initWebcam();
                speakWithAnimation(`Hello ${userName}, ready for your interview? Let's begin!`, async () => {
                    isInterviewMode = true;
                    console.log('Fetching initial questions');
                    const success = await generateQuestions(userData.job_description, userData.resume_text, '', false);
                    if (success) {
                        console.log('Questions generated, asking first question');
                        askNextQuestion();
                    } else {
                        console.error('Failed to generate questions');
                        speakWithAnimation("I couldn't generate questions. Please try again.", () => {
                            window.location.href = '/index.html';
                        }, 'talking');
                    }
                }, 'bowGreeet');
            } else {
                speakWithAnimation("Welcome! I couldn't find your details. Please submit your information.", () => {
                    window.location.href = '/index.html';
                }, 'talking');
            }
        }, (xhr) => {}, (error) => {
            console.error('Error loading model:', error);
            alert("Failed to load 3D model. Please refresh the page.");
        });

        async function fetchUserData() {
            try {
                const response = await fetch('http://127.0.0.1:5000/get_user_data', {
                    method: 'GET',
                    headers: { 'Accept': 'application/json' }
                });
                const result = await response.json();
                console.log('fetchUserData response:', result);
                if (result.status === 'success' && result.data && result.data.length > 0) {
                    return result.data[result.data.length - 1];
                } else {
                    console.error('No user data found:', result);
                    return null;
                }
            } catch (error) {
                console.error('Error fetching user data:', error);
                return null;
            }
        }

        async function generateQuestions(jobDescription, resumeText, previousAnswer = '', isFollowUp = false) {
            try {
                const numQuestions = Math.floor(Math.random() * 2) + 3;
                console.log('Generating questions:', { numQuestions, jobDescription, previousAnswer, isFollowUp });
                const response = await fetch('http://127.0.0.1:5000/generate_questions', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        job_description: jobDescription,
                        previous_answer: previousAnswer,
                        num_questions: numQuestions,
                        is_follow_up: isFollowUp
                    })
                });
                const result = await response.json();
                console.log('generateQuestions response:', result);
                if (result.status === 'success' && Array.isArray(result.questions) && result.questions.length > 0) {
                    if (isFollowUp) {
                        const oldLength = interviewQuestions.length;
                        interviewQuestions = interviewQuestions.concat(result.questions);
                        currentQuestionIndex = oldLength;
                        console.log(`Appended ${result.questions.length} follow-up questions. New total: ${interviewQuestions.length}`);
                    } else {
                        interviewQuestions = result.questions;
                        currentQuestionIndex = 0;
                    }
                    return true;
                } else {
                    console.error('Invalid questions response:', result);
                    return false;
                }
            } catch (err) {
                console.error('Error generating questions:', err);
                return false;
            }
        }

        async function fetchFromGemini(promptText) {
            try {
                console.log('Fetching from Gemini with prompt:', promptText.substring(0, 100) + '...');
                const response = await fetch('http://127.0.0.1:5000/generate_response', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt: promptText })
                });
                const data = await response.json();
                console.log('Gemini response:', data);
                return data.response || "I'm sorry, I couldn't understand that.";
            } catch (error) {
                console.error('Error fetching from Gemini:', error);
                return "Sorry, there was an error processing your request.";
            }
        }

        async function generateInterviewSummary(interviewAnswers) {
            const allAnswersText = interviewAnswers.map((item, idx) => 
                `Q${idx+1}: ${item.question}\nA${idx+1}: ${item.answer}\n`
            ).join("\n");

            const summaryPrompt = `
                You are an experienced interview evaluator. Here is a transcript of a candidate's virtual interview. 
                Provide a brief evaluation of:
                - Technical Knowledge
                - Communication Skills
                - Confidence Level
                - Areas to Improve
                Keep the evaluation concise, with one sentence per category, and a one-sentence hiring recommendation.
                Interview transcript:
                ${allAnswersText}
            `;

            try {
                const response = await fetch('http://127.0.0.1:5000/generate_response', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt: summaryPrompt })
                });
                const data = await response.json();
                console.log('Summary response:', data);
                return data.response || "Summary generation failed.";
            } catch (error) {
                console.error('Error generating summary:', error);
                return "There was an error creating the interview summary.";
            }
        }

        async function generateFeedbackForAnswer(question, answer) {
            const prompt = `
                You are a professional interviewer. Given the following interview question and the candidate's answer:
                Question: ${question}
                Answer: ${answer}
                Generate a short, professional response as the interviewer would say after hearing the answer. 
                Keep it to 1-2 sentences. Be neutral and constructive: praise good aspects if any, suggest improvements if needed, or acknowledge if the answer is insufficient (e.g., if they say "I don't know", suggest "That's okay, let's move on."). 
                If the answer seems off-topic or unclear, gently redirect. Make it natural and encouraging overall, but not always overly positive for weak answers.
            `;
            return await fetchFromGemini(prompt);
        }

        async function speakWithAnimation(text, callback, animationType = 'none') {
            const resolvedText = cleanText(text.replace("{name}", userName));
            isSpeaking = true;
            if (bowGreeetAction) bowGreeetAction.stop();
            if (thinkingAction) thinkingAction.fadeOut(0.1);
            if (talking2Action) talking2Action.fadeOut(0.1);
            if (idleAction && !isSpeaking && animationType === 'none') {
                idleAction.reset().fadeIn(0.1).play();
            }
            if (model) model.rotation.y = 0;
            if (rootBone) rootBone.rotation.y = 0;
            if (animationType === 'bowGreeet' && bowGreeetAction) {
                if (idleAction) idleAction.fadeOut(0.1);
                bowGreeetAction.reset().fadeIn(0.1).play();
                mixer.addEventListener('finished', onAnimationFinished);
            } else if (animationType === 'thinking' && thinkingAction) {
                if (idleAction) idleAction.fadeOut(0.1);
                thinkingAction.reset().fadeIn(0.1).play();
            } else if (animationType === 'talking' && talking2Action) {
                if (idleAction) idleAction.fadeOut(0.1);
                talking2Action.reset().fadeIn(0.1).play();
            } else {
                if (idleAction) idleAction.reset().fadeIn(0.1).play();
            }

            const questionDisplay = document.getElementById('questionDisplay');
            if (text.startsWith('Question')) {
                questionDisplay.innerText = resolvedText;
            }

            try {
                console.log('Requesting TTS from backend:', resolvedText);
                const response = await fetch('http://127.0.0.1:5000/tts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: resolvedText })
                });
                if (!response.ok) {
                    throw new Error(`TTS endpoint error: ${response.status} - ${await response.text()}`);
                }

                const blob = await response.blob();
                const url = URL.createObjectURL(blob);
                const audio = new Audio(url);
                audio.onplay = () => {
                    if (animationType === 'none' && talking2Action) {
                        if (idleAction) idleAction.fadeOut(0.1);
                        talking2Action.reset().fadeIn(0.1).play();
                    }
                    animateMouthDuringSpeech();
                };
                audio.onended = () => {
                    isSpeaking = false;
                    if (headMesh && headMesh.morphTargetInfluences) {
                        headMesh.morphTargetInfluences[15] = 0;
                    }
                    if (thinkingAction) thinkingAction.fadeOut(0.1);
                    if (talking2Action) talking2Action.fadeOut(0.1);
                    if (idleAction) {
                        if (model) model.rotation.y = 0;
                        idleAction.reset().fadeIn(0.1).play();
                    }
                    questionDisplay.innerText = '';
                    if (callback) callback();
                };
                audio.onerror = (e) => {
                    console.error("Audio playback error:", e);
                    isSpeaking = false;
                    tryWebSpeechFallback(resolvedText, callback, animationType);
                };
                audio.play();
            } catch (error) {
                console.error("TTS failed:", error);
                tryWebSpeechFallback(resolvedText, callback, animationType);
            }
        }

        function tryWebSpeechFallback(text, callback, animationType) {
            if (!window.speechSynthesis) {
                console.error("Web Speech API not supported");
                isSpeaking = false;
                if (thinkingAction) thinkingAction.fadeOut(0.1);
                if (talking2Action) talking2Action.fadeOut(0.1);
                if (idleAction) {
                    if (model) model.rotation.y = 0;
                    idleAction.reset().fadeIn(0.1).play();
                }
                document.getElementById('questionDisplay').innerText = '';
                alert(text);
                if (callback) callback();
                return;
            }

            const utterance = new SpeechSynthesisUtterance(text);
            const femaleVoice = getFemaleVoice();
            if (femaleVoice) {
                utterance.voice = femaleVoice;
            }
            utterance.lang = 'en-US';
            utterance.volume = 1.0;
            utterance.rate = 1.0;
            utterance.pitch = 1.2;

            utterance.onstart = () => {
                if (animationType === 'none' && talking2Action) {
                    if (idleAction) idleAction.fadeOut(0.1);
                    talking2Action.reset().fadeIn(0.1).play();
                }
                animateMouthDuringSpeech();
            };
            utterance.onend = () => {
                isSpeaking = false;
                if (headMesh && headMesh.morphTargetInfluences) {
                    headMesh.morphTargetInfluences[15] = 0;
                }
                if (thinkingAction) thinkingAction.fadeOut(0.1);
                if (talking2Action) talking2Action.fadeOut(0.1);
                if (idleAction) {
                    if (model) model.rotation.y = 0;
                    idleAction.reset().fadeIn(0.1).play();
                }
                document.getElementById('questionDisplay').innerText = '';
                if (callback) callback();
            };
            utterance.onerror = (e) => {
                console.error("Web Speech API error:", e);
                isSpeaking = false;
                if (thinkingAction) thinkingAction.fadeOut(0.1);
                if (talking2Action) talking2Action.fadeOut(0.1);
                if (idleAction) {
                    if (model) model.rotation.y = 0;
                    idleAction.reset().fadeIn(0.1).play();
                }
                document.getElementById('questionDisplay').innerText = '';
                alert(text);
                if (callback) callback();
            };

            if (window.speechSynthesis.getVoices().length === 0) {
                window.speechSynthesis.onvoiceschanged = () => {
                    const femaleVoice = getFemaleVoice();
                    if (femaleVoice) {
                        utterance.voice = femaleVoice;
                    }
                    window.speechSynthesis.speak(utterance);
                };
            } else {
                window.speechSynthesis.speak(utterance);
            }
        }

        function onAnimationFinished(event) {
            if (event.action === bowGreeetAction) {
                if (model) model.rotation.y = 0;
                if (rootBone) rootBone.rotation.y = 0;
                if (idleAction) {
                    idleAction.reset().fadeIn(0.1).play();
                }
                mixer.removeEventListener('finished', onAnimationFinished);
            }
        }

        function animateMouthDuringSpeech() {
            if (!headMesh || !isSpeaking) return;
            if (!headMesh.morphTargetInfluences || headMesh.morphTargetInfluences[15] === undefined) {
                return;
            }
            const time = performance.now() / 1000;
            const value = (Math.sin(time * 6) + 1) / 2 * 0.8;
            headMesh.morphTargetInfluences[15] = value;
            requestAnimationFrame(animateMouthDuringSpeech);
        }

        function animateBlink(delta) {
            if (!headMesh || !headMesh.morphTargetInfluences || eyesClosedIndex === -1) return;
            blinkTimer += delta;
            if (blinkState === 'open' && blinkTimer >= nextBlink) {
                blinkState = 'closing';
                blinkTimer = 0;
            } else if (blinkState === 'closing' && blinkTimer >= blinkDuration / 2) {
                blinkState = 'closed';
                headMesh.morphTargetInfluences[eyesClosedIndex] = 1;
                blinkTimer = 0;
            } else if (blinkState === 'closed' && blinkTimer >= blinkDuration / 4) {
                blinkState = 'opening';
                blinkTimer = 0;
            } else if (blinkState === 'opening' && blinkTimer >= blinkDuration / 2) {
                blinkState = 'open';
                headMesh.morphTargetInfluences[eyesClosedIndex] = 0;
                blinkTimer = 0;
                nextBlink = Math.random() * 3 + 2;
            }
            if (blinkState === 'closing') {
                headMesh.morphTargetInfluences[eyesClosedIndex] = Math.min(1, blinkTimer / (blinkDuration / 2));
            } else if (blinkState === 'opening') {
                headMesh.morphTargetInfluences[eyesClosedIndex] = Math.max(0, 1 - blinkTimer / (blinkDuration / 2));
            }
        }

        function startListening() {
            if (isListening || isSpeaking) {
                console.log('Cannot start listening: already listening or speaking');
                return;
            }
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.error('Speech recognition not supported');
                alert("Speech recognition not supported by your browser.");
                return;
            }
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            fullTranscript = '';
            let lastSpeechTime = Date.now();
            let maxListeningTimer = null;

            recognition.onstart = () => {
                console.log('Speech recognition started');
                isListening = true;
                document.getElementById('toggleListenButton').textContent = "Stop Listening";
                maxListeningTimer = setTimeout(() => {
                    console.log('Max listening time reached, forcing stop');
                    stopAndProcess();
                }, MAX_LISTENING_TIME);
            };

            recognition.onresult = (event) => {
                clearTimeout(silenceTimer);
                lastSpeechTime = Date.now();
                fullTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    fullTranscript += event.results[i][0].transcript;
                }
                console.log('Interim transcript:', fullTranscript);
                silenceTimer = setTimeout(() => {
                    console.log('Silence detected for 6 seconds, stopping recognition');
                    stopAndProcess();
                }, SILENCE_TIMEOUT);
            };

            recognition.onerror = (e) => {
                console.error('Speech recognition error:', e.error);
                clearTimeout(silenceTimer);
                clearTimeout(maxListeningTimer);
                if (e.error === 'no-speech' || e.error === 'audio-capture' || e.error === 'not-allowed') {
                    console.log('Stopping recognition due to error:', e.error);
                    stopAndProcess();
                } else {
                    stopListening();
                    alert(`Speech recognition error: ${e.error}. Please try again.`);
                }
            };

            recognition.onend = () => {
                console.log('Speech recognition ended');
                clearTimeout(maxListeningTimer);
                if (isListening) {
                    console.log('Attempting to restart recognition');
                    try {
                        recognition.start();
                    } catch (err) {
                        console.error('Error restarting recognition:', err);
                        stopListening();
                        alert('Failed to restart speech recognition. Please try again.');
                    }
                } else {
                    console.log('Recognition stopped, updating button');
                    document.getElementById('toggleListenButton').textContent = "Start Listening";
                }
            };

            try {
                recognition.start();
                console.log('Speech recognition initiated');
            } catch (err) {
                console.error('Error starting speech recognition:', err);
                alert("Failed to start speech recognition. Please check microphone permissions.");
                stopListening();
            }
        }

        async function stopAndProcess() {
            console.log('Stopping and processing answer');
            isListening = false;
            if (recognition) {
                try {
                    recognition.stop();
                } catch (err) {
                    console.error('Error stopping recognition:', err);
                }
                recognition = null;
            }
            clearTimeout(silenceTimer);
            console.log('Processed transcript:', fullTranscript.trim());
            if (isInterviewMode && fullTranscript.trim()) {
                const transcriptLower = fullTranscript.toLowerCase().trim();
                if (transcriptLower.includes('repeat') || transcriptLower.includes('say again') || transcriptLower.includes('repeat the question')) {
                    // Repeat the current question
                    speakWithAnimation(`Question ${questionNumber}: ${interviewQuestions[currentQuestionIndex]}`, () => {
                        setTimeout(startListening, 500);
                    }, 'talking');
                    return;
                }

                interviewAnswers.push({
                    question: interviewQuestions[currentQuestionIndex],
                    answer: fullTranscript.trim()
                });

                // Generate professional feedback based on the answer
                const feedback = await generateFeedbackForAnswer(interviewQuestions[currentQuestionIndex], fullTranscript.trim());

                if (currentQuestionIndex >= interviewQuestions.length - 1) {
                    speakWithAnimation(
                        feedback + " That's all! Great job! Let's prepare your summary.",
                        async () => {
                            isInterviewMode = false;
                            if (screenRecorder && screenRecorder.state !== "inactive") {
                                screenRecorder.stop();
                            }
                            console.log('Storing answers:', interviewAnswers);
                            try {
                                await fetch('http://127.0.0.1:5000/store_answers', {
                                    method: 'POST',
                                    headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify({ answers: interviewAnswers })
                                });
                            } catch (err) {
                                console.error('Error storing answers:', err);
                            }
                            await finishInterview();
                        },
                        'bowGreeet'
                    );
                } else {
                    // Optionally generate follow-up
                    let followUpGenerated = false;
                    if (Math.random() < 0.5) {
                        console.log('Generating follow-up question based on:', fullTranscript.trim());
                        const followUpSuccess = await generateQuestions(
                            userData.job_description,
                            userData.resume_text,
                            fullTranscript.trim(),
                            true
                        );
                        followUpGenerated = followUpSuccess;
                    }
                    speakWithAnimation(
                        feedback,
                        () => {
                            currentQuestionIndex++;
                            questionNumber++;
                            askNextQuestion();
                        },
                        'talking'
                    );
                }
            } else {
                askNextQuestion();
            }
        }

        function stopListening() {
            console.log('Manually stopping listening');
            isListening = false;
            if (recognition) {
                try {
                    recognition.stop();
                } catch (err) {
                    console.error('Error stopping recognition:', err);
                }
                recognition = null;
            }
            clearTimeout(silenceTimer);
            document.getElementById('toggleListenButton').textContent = "Start Listening";
        }

        function toggleListening() {
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        document.getElementById('toggleListenButton').addEventListener('click', toggleListening);
        document.getElementById('viewReportButton').addEventListener('click', () => {
            window.location.href = '/summary.html';
        });

        document.addEventListener("visibilitychange", () => {
            if (document.hidden && isInterviewMode) {
                console.log('Tab hidden, ending interview');
                isInterviewMode = false;
                if (screenRecorder && screenRecorder.state !== "inactive") {
                    screenRecorder.stop();
                }
                speakWithAnimation("Interview ended due to tab change.", () => {
                    window.location.href = '/index.html';
                }, 'talking');
                currentQuestionIndex = interviewQuestions.length;
                interviewAnswers = [];
            }
        });

        function askNextQuestion() {
            if (currentQuestionIndex >= interviewQuestions.length) {
                speakWithAnimation(
                    "That's all! Great job! Let's prepare your summary.",
                    async () => {
                        isInterviewMode = false;
                        if (screenRecorder && screenRecorder.state !== "inactive") {
                            screenRecorder.stop();
                        }
                        console.log('Storing answers:', interviewAnswers);
                        try {
                            await fetch('http://127.0.0.1:5000/store_answers', {
                                method: 'POST',
                                headers: { 'Content-Type': 'application/json' },
                                body: JSON.stringify({ answers: interviewAnswers })
                            });
                        } catch (err) {
                            console.error('Error storing answers:', err);
                        }
                        await finishInterview();
                    },
                    'bowGreeet'
                );
                return;
            }
            const question = interviewQuestions[currentQuestionIndex];
            console.log('Asking question:', question);
            speakWithAnimation(`Question ${questionNumber}: ${question}`, () => {
                setTimeout(startListening, 500);
            }, 'talking');
        }

        async function finishInterview() {
            try {
                console.log('Generating final summary');
                document.getElementById('viewReportButton').style.display = 'block';
                const summaryResponse = await fetch('/generate_summary', { 
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                const summaryData = await summaryResponse.json();
                if (summaryData.status === 'success') {
                    const summary = await generateInterviewSummary(interviewAnswers);
                    speakWithAnimation("Here's your interview summary.", () => {
                        speakWithAnimation(summary, () => {}, 'talking');
                    }, 'talking');
                } else {
                    console.error('Error generating summary:', summaryData.error);
                    speakWithAnimation("Summary generation failed, but you can view the report.", () => {}, 'talking');
                }
            } catch (e) {
                console.error('Error finishing interview:', e);
                speakWithAnimation("Error preparing summary, but you can view the report.", () => {}, 'talking');
                document.getElementById('viewReportButton').style.display = 'block';
            }
        }

        function animate() {
            requestAnimationFrame(animate);
            if (mixer) {
                const delta = clock.getDelta();
                mixer.update(delta);
                animateBlink(delta);
                if (mixer._actions.every(action => !action.isRunning() || action._clip.name.toLowerCase().includes('idle'))) {
                    if (model) model.rotation.y = 0;
                    if (rootBone) rootBone.rotation.y = 0;
                }
            }
            renderer.render(scene, camera);
        }

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth * 0.7 / (window.innerHeight * 0.7); // Match increased three-container width
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth * 0.7, window.innerHeight * 0.7);
        });

        animate();
    </script>
</body>
</html>
